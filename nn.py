# -*- coding: utf-8 -*-from keras.models import Sequential  from keras.layers.core import Dense, Activation,Dropoutfrom keras.layers.recurrent import LSTMfrom keras.regularizers import *import pandas as pdimport numpy as npfrom keras.utils import np_utilsfrom keras.callbacks import EarlyStoppingnum4DF = pd.read_csv("data/num4.csv",names=("1","2","3","4"))for i in xrange(1,5):	num4DF["answer"+str(i)] = num4DF[str(i)].shift(-1)# 過去5回分かを参照するfor i in xrange(1,6):	num4DF["befor1"+str(i)] = num4DF["1"].shift(i)	num4DF["befor2"+str(i)] = num4DF["2"].shift(i)	num4DF["befor3"+str(i)] = num4DF["3"].shift(i)	num4DF["befor4"+str(i)] = num4DF["4"].shift(i)# 過去分が無い(=先頭の5件)と答えが無い(=最新の1件)は教師データから除外するnum4DF.dropna(subset=["befor15"],inplace=True)num4DF.dropna(subset=["answer1"],inplace=True)# 1~4桁目を質的変数とみなして変換trainDF = pd.get_dummies(num4DF["1"])train2Array = pd.get_dummies(num4DF["2"])trainDF = pd.concat([trainDF, train2Array], axis=1)train3Array = pd.get_dummies(num4DF["3"])trainDF = pd.concat([trainDF, train3Array], axis=1)train4Array = pd.get_dummies(num4DF["4"])trainDF = pd.concat([trainDF, train4Array], axis=1)# 過去何回分かを参照するfor i in xrange(1,5):	trainDF = pd.concat([trainDF, pd.get_dummies(num4DF["befor1"+str(i)])], axis=1)	trainDF = pd.concat([trainDF, pd.get_dummies(num4DF["befor2"+str(i)])], axis=1)	trainDF = pd.concat([trainDF, pd.get_dummies(num4DF["befor3"+str(i)])], axis=1)	trainDF = pd.concat([trainDF, pd.get_dummies(num4DF["befor4"+str(i)])], axis=1)# 入力する値を0以上1以下になるように正規化trainDF = trainDF.apply(lambda x: (x-x.min())/(x.max()-x.min()), axis=0).fillna(0)training_data = np.array(trainDF.values.tolist())# 次の回に出てきた数を1桁ずつ答えにして学習させてみるy_train1 = np.array(pd.get_dummies(num4DF["answer1"]).values.tolist())y_train2 = np.array(pd.get_dummies(num4DF["answer2"]).values.tolist())y_train3 = np.array(pd.get_dummies(num4DF["answer3"]).values.tolist())y_train4 = np.array(pd.get_dummies(num4DF["answer4"]).values.tolist())# 入力する次元は列数分col_num = training_data.shape[1]def learning(answer,weightname):	model = Sequential()	model.add(Dense(col_num, init='glorot_uniform',input_dim=col_num,				activation='relu', W_regularizer=l1l2(l1=0.0001, l2=0.0001)))	model.add(Dropout(0.5))	model.add(Dense(col_num*2, init='glorot_uniform', activation='relu'))	model.add(Dropout(0.5))	model.add(Dense(col_num*4, init='glorot_uniform', activation='relu'))	model.add(Dropout(0.5))	model.add(Dense(10, activation='softmax'))	model.compile(optimizer='Adadelta',	              loss='categorical_crossentropy',	              metrics=['accuracy'])	print(model.summary())	model.fit(training_data, answer, batch_size=600, nb_epoch=3000, validation_split=0.05)  	model.save_weights("weight/"+weightname+'.hdf5')learning(y_train1,"num1")learning(y_train2,"num2")learning(y_train3,"num3")learning(y_train4,"num4")